{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "# standard library\n",
    "import os\n",
    " \n",
    "# third-party library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlc_practical_prologue as helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = helper.generate_pair_sets(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline (Full contected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline(\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=392, out_features=256, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(baseline, self).__init__()\n",
    "        self.out = nn.Sequential( nn.Linear(392, 256), nn.Sigmoid(), nn.Linear(256, 64), nn.Sigmoid(), nn.Linear(64 , 2), nn.Sigmoid())   # fully connected layer, output 10 classes\n",
    " \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print(x.size())\n",
    "        output = self.out(x)\n",
    "        return output, x  \n",
    "baseline = baseline()\n",
    "print(baseline)  # net architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.6671 | train accuracy: 0.6100 | test accuracy: 0.51\n",
      "Epoch:  1 | train loss: 0.6508 | train accuracy: 0.6100 | test accuracy: 0.56\n",
      "Epoch:  2 | train loss: 0.6246 | train accuracy: 0.7600 | test accuracy: 0.72\n",
      "Epoch:  3 | train loss: 0.5926 | train accuracy: 0.7500 | test accuracy: 0.80\n",
      "Epoch:  4 | train loss: 0.5667 | train accuracy: 0.7700 | test accuracy: 0.80\n",
      "Epoch:  5 | train loss: 0.5438 | train accuracy: 0.8000 | test accuracy: 0.83\n",
      "Epoch:  6 | train loss: 0.5276 | train accuracy: 0.8100 | test accuracy: 0.86\n",
      "Epoch:  7 | train loss: 0.5059 | train accuracy: 0.8400 | test accuracy: 0.84\n",
      "Epoch:  8 | train loss: 0.4915 | train accuracy: 0.8600 | test accuracy: 0.85\n",
      "Epoch:  9 | train loss: 0.4825 | train accuracy: 0.8500 | test accuracy: 0.85\n",
      "Epoch:  10 | train loss: 0.4727 | train accuracy: 0.8500 | test accuracy: 0.85\n",
      "Epoch:  11 | train loss: 0.4597 | train accuracy: 0.8700 | test accuracy: 0.84\n",
      "Epoch:  12 | train loss: 0.4609 | train accuracy: 0.8500 | test accuracy: 0.80\n",
      "Epoch:  13 | train loss: 0.4375 | train accuracy: 0.9300 | test accuracy: 0.86\n",
      "Epoch:  14 | train loss: 0.4232 | train accuracy: 0.9200 | test accuracy: 0.85\n",
      "Epoch:  15 | train loss: 0.4157 | train accuracy: 0.9500 | test accuracy: 0.86\n",
      "Epoch:  16 | train loss: 0.4196 | train accuracy: 0.9200 | test accuracy: 0.81\n",
      "Epoch:  17 | train loss: 0.4112 | train accuracy: 0.9300 | test accuracy: 0.85\n",
      "Epoch:  18 | train loss: 0.4115 | train accuracy: 0.9200 | test accuracy: 0.81\n",
      "Epoch:  19 | train loss: 0.4095 | train accuracy: 0.9200 | test accuracy: 0.85\n",
      "Epoch:  20 | train loss: 0.3878 | train accuracy: 0.9500 | test accuracy: 0.84\n",
      "Epoch:  21 | train loss: 0.3874 | train accuracy: 0.9500 | test accuracy: 0.83\n",
      "Epoch:  22 | train loss: 0.3829 | train accuracy: 0.9600 | test accuracy: 0.82\n",
      "Epoch:  23 | train loss: 0.3789 | train accuracy: 0.9600 | test accuracy: 0.86\n",
      "Epoch:  24 | train loss: 0.3687 | train accuracy: 0.9700 | test accuracy: 0.85\n",
      "Epoch:  25 | train loss: 0.3750 | train accuracy: 0.9700 | test accuracy: 0.86\n",
      "Epoch:  26 | train loss: 0.3661 | train accuracy: 0.9700 | test accuracy: 0.84\n",
      "Epoch:  27 | train loss: 0.3609 | train accuracy: 0.9700 | test accuracy: 0.87\n",
      "Epoch:  28 | train loss: 0.3561 | train accuracy: 0.9700 | test accuracy: 0.82\n",
      "Epoch:  29 | train loss: 0.3571 | train accuracy: 0.9800 | test accuracy: 0.81\n",
      "Epoch:  30 | train loss: 0.3463 | train accuracy: 0.9800 | test accuracy: 0.81\n",
      "Epoch:  31 | train loss: 0.3480 | train accuracy: 0.9800 | test accuracy: 0.86\n",
      "Epoch:  32 | train loss: 0.3447 | train accuracy: 0.9800 | test accuracy: 0.84\n",
      "Epoch:  33 | train loss: 0.3400 | train accuracy: 0.9800 | test accuracy: 0.83\n",
      "Epoch:  34 | train loss: 0.3359 | train accuracy: 0.9800 | test accuracy: 0.83\n",
      "Epoch:  35 | train loss: 0.3320 | train accuracy: 0.9800 | test accuracy: 0.86\n",
      "Epoch:  36 | train loss: 0.3313 | train accuracy: 0.9900 | test accuracy: 0.84\n",
      "Epoch:  37 | train loss: 0.3283 | train accuracy: 1.0000 | test accuracy: 0.84\n",
      "Epoch:  38 | train loss: 0.3237 | train accuracy: 1.0000 | test accuracy: 0.84\n",
      "Epoch:  39 | train loss: 0.3229 | train accuracy: 1.0000 | test accuracy: 0.84\n",
      "Epoch:  40 | train loss: 0.3235 | train accuracy: 1.0000 | test accuracy: 0.84\n",
      "Epoch:  41 | train loss: 0.3211 | train accuracy: 1.0000 | test accuracy: 0.84\n",
      "Epoch:  42 | train loss: 0.3217 | train accuracy: 1.0000 | test accuracy: 0.87\n",
      "Epoch:  43 | train loss: 0.3207 | train accuracy: 1.0000 | test accuracy: 0.86\n",
      "Epoch:  44 | train loss: 0.3199 | train accuracy: 1.0000 | test accuracy: 0.87\n",
      "Epoch:  45 | train loss: 0.3190 | train accuracy: 1.0000 | test accuracy: 0.86\n",
      "Epoch:  46 | train loss: 0.3188 | train accuracy: 1.0000 | test accuracy: 0.86\n",
      "Epoch:  47 | train loss: 0.3185 | train accuracy: 1.0000 | test accuracy: 0.85\n",
      "Epoch:  48 | train loss: 0.3192 | train accuracy: 1.0000 | test accuracy: 0.86\n",
      "Epoch:  49 | train loss: 0.3177 | train accuracy: 1.0000 | test accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "mini_batch_size=100\n",
    "EPOCH = 50\n",
    "LR = 0.001              # learning rate\n",
    "step = 0\n",
    "\n",
    "optimizer = torch.optim.Adam(baseline.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "criterion = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for b in range(0, train_input.size(0), mini_batch_size):   # gives batch data, normalize x when iterate train_loader\n",
    "        \n",
    "        x_tr = train_input.narrow(0, b, mini_batch_size)\n",
    "        y_tr = train_target.narrow(0, b, mini_batch_size)#.narrow(1, 0, 1).squeeze()\n",
    "        x_tr = Variable(x_tr)   # batch x\n",
    "        y_tr = Variable(y_tr)   # batch y\n",
    "#         x_tr.requires_grad_()\n",
    "        output,_ = baseline(x_tr)               # cnn output\n",
    "#         print(output)\n",
    "        loss = criterion(output, y_tr)   # cross entropy loss\n",
    "#         print(loss)\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "#         print(x_tr.grad)\n",
    "        optimizer.step()                # apply gradients\n",
    "        \n",
    "    x_te = test_input.narrow(0, b, mini_batch_size)#.narrow(1, 0, 1)\n",
    "    y_te = test_target.narrow(0, b, mini_batch_size)#.narrow(1, 0, 1).squeeze()\n",
    "    x_te = Variable(x_te)   \n",
    "    y_te = Variable(y_te)   \n",
    "\n",
    "    \n",
    "    y_tr_pred = torch.max(output, 1)[1].data.squeeze()\n",
    "    acc_tr = (y_tr_pred == y_tr).sum().data.item() / y_tr.size(0)\n",
    "    \n",
    "    test_output, last_layer = baseline(x_te)    \n",
    "    y_te_pred = torch.max(test_output, 1)[1].data.squeeze()\n",
    "    acc_te = (y_te_pred == y_te).sum().data.item() / y_te.size(0)\n",
    "    print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.item(), '| train accuracy: %.4f' % acc_tr, '| test accuracy: %.2f' % acc_te)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Sharing(with conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(2, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=520, out_features=256, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (2, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=2,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1                   # filter movement/step\n",
    "                              # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=3),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 3 , 1, 1),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.out = nn.Sequential( nn.Linear(520, 256), nn.Sigmoid(), nn.Linear(256, 64), nn.Sigmoid(), nn.Linear(64 , 2), nn.Sigmoid())   # fully connected layer, output 10 classes\n",
    " \n",
    "    def forward(self, x):\n",
    "        x_ = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "#         print(x.size())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_ = x_.view(x_.size(0), -1)\n",
    "#         print(torch.cat((x, x_), 1).size())\n",
    "        output = self.out(torch.cat((x, x_), 1))\n",
    "        return output, x    # return x for visualization  \n",
    "cnn = CNN()\n",
    "print(cnn)  # net architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.5023 | train accuracy: 0.8700 | test accuracy: 0.79\n",
      "Epoch:  1 | train loss: 0.4738 | train accuracy: 0.9000 | test accuracy: 0.82\n",
      "Epoch:  2 | train loss: 0.4595 | train accuracy: 0.9100 | test accuracy: 0.82\n",
      "Epoch:  3 | train loss: 0.4412 | train accuracy: 0.9200 | test accuracy: 0.84\n",
      "Epoch:  4 | train loss: 0.4342 | train accuracy: 0.9100 | test accuracy: 0.79\n",
      "Epoch:  5 | train loss: 0.4243 | train accuracy: 0.9300 | test accuracy: 0.83\n",
      "Epoch:  6 | train loss: 0.4101 | train accuracy: 0.9400 | test accuracy: 0.80\n",
      "Epoch:  7 | train loss: 0.3980 | train accuracy: 0.9500 | test accuracy: 0.82\n",
      "Epoch:  8 | train loss: 0.3828 | train accuracy: 0.9600 | test accuracy: 0.83\n",
      "Epoch:  9 | train loss: 0.3759 | train accuracy: 0.9600 | test accuracy: 0.80\n",
      "Epoch:  10 | train loss: 0.3649 | train accuracy: 0.9700 | test accuracy: 0.83\n",
      "Epoch:  11 | train loss: 0.3588 | train accuracy: 0.9800 | test accuracy: 0.82\n",
      "Epoch:  12 | train loss: 0.3684 | train accuracy: 0.9700 | test accuracy: 0.82\n",
      "Epoch:  13 | train loss: 0.3803 | train accuracy: 0.9600 | test accuracy: 0.81\n",
      "Epoch:  14 | train loss: 0.4152 | train accuracy: 0.9300 | test accuracy: 0.79\n",
      "Epoch:  15 | train loss: 0.4128 | train accuracy: 0.9100 | test accuracy: 0.75\n",
      "Epoch:  16 | train loss: 0.3703 | train accuracy: 0.9700 | test accuracy: 0.74\n",
      "Epoch:  17 | train loss: 0.4112 | train accuracy: 0.9200 | test accuracy: 0.82\n",
      "Epoch:  18 | train loss: 0.4509 | train accuracy: 0.8500 | test accuracy: 0.77\n",
      "Epoch:  19 | train loss: 0.3930 | train accuracy: 0.9400 | test accuracy: 0.79\n",
      "Epoch:  20 | train loss: 0.3637 | train accuracy: 0.9700 | test accuracy: 0.83\n",
      "Epoch:  21 | train loss: 0.3527 | train accuracy: 0.9900 | test accuracy: 0.82\n",
      "Epoch:  22 | train loss: 0.3484 | train accuracy: 0.9900 | test accuracy: 0.84\n",
      "Epoch:  23 | train loss: 0.3461 | train accuracy: 0.9900 | test accuracy: 0.84\n",
      "Epoch:  24 | train loss: 0.3336 | train accuracy: 1.0000 | test accuracy: 0.86\n",
      "Epoch:  25 | train loss: 0.3302 | train accuracy: 1.0000 | test accuracy: 0.87\n",
      "Epoch:  26 | train loss: 0.3268 | train accuracy: 1.0000 | test accuracy: 0.85\n",
      "Epoch:  27 | train loss: 0.3244 | train accuracy: 1.0000 | test accuracy: 0.88\n",
      "Epoch:  28 | train loss: 0.3221 | train accuracy: 1.0000 | test accuracy: 0.85\n",
      "Epoch:  29 | train loss: 0.3201 | train accuracy: 1.0000 | test accuracy: 0.84\n",
      "Epoch:  30 | train loss: 0.3196 | train accuracy: 1.0000 | test accuracy: 0.87\n",
      "Epoch:  31 | train loss: 0.3192 | train accuracy: 1.0000 | test accuracy: 0.88\n",
      "Epoch:  32 | train loss: 0.3186 | train accuracy: 1.0000 | test accuracy: 0.87\n",
      "Epoch:  33 | train loss: 0.3180 | train accuracy: 1.0000 | test accuracy: 0.86\n",
      "Epoch:  34 | train loss: 0.3177 | train accuracy: 1.0000 | test accuracy: 0.87\n",
      "Epoch:  35 | train loss: 0.3174 | train accuracy: 1.0000 | test accuracy: 0.87\n",
      "Epoch:  36 | train loss: 0.3172 | train accuracy: 1.0000 | test accuracy: 0.86\n",
      "Epoch:  37 | train loss: 0.3170 | train accuracy: 1.0000 | test accuracy: 0.87\n",
      "Epoch:  38 | train loss: 0.3169 | train accuracy: 1.0000 | test accuracy: 0.87\n",
      "Epoch:  39 | train loss: 0.3167 | train accuracy: 1.0000 | test accuracy: 0.86\n",
      "Epoch:  40 | train loss: 0.3165 | train accuracy: 1.0000 | test accuracy: 0.87\n",
      "Epoch:  41 | train loss: 0.3164 | train accuracy: 1.0000 | test accuracy: 0.86\n",
      "Epoch:  42 | train loss: 0.3163 | train accuracy: 1.0000 | test accuracy: 0.85\n",
      "Epoch:  43 | train loss: 0.3161 | train accuracy: 1.0000 | test accuracy: 0.86\n",
      "Epoch:  44 | train loss: 0.3160 | train accuracy: 1.0000 | test accuracy: 0.86\n",
      "Epoch:  45 | train loss: 0.3159 | train accuracy: 1.0000 | test accuracy: 0.87\n",
      "Epoch:  46 | train loss: 0.3158 | train accuracy: 1.0000 | test accuracy: 0.87\n",
      "Epoch:  47 | train loss: 0.3157 | train accuracy: 1.0000 | test accuracy: 0.86\n",
      "Epoch:  48 | train loss: 0.3156 | train accuracy: 1.0000 | test accuracy: 0.86\n",
      "Epoch:  49 | train loss: 0.3155 | train accuracy: 1.0000 | test accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "mini_batch_size=100\n",
    "EPOCH = 50\n",
    "LR = 0.001              # learning rate\n",
    "step = 0\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "criterion = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for b in range(0, train_input.size(0), mini_batch_size):   # gives batch data, normalize x when iterate train_loader\n",
    "        \n",
    "        x_tr = train_input.narrow(0, b, mini_batch_size)\n",
    "        y_tr = train_target.narrow(0, b, mini_batch_size)#.narrow(1, 0, 1).squeeze()\n",
    "        x_tr = Variable(x_tr)   # batch x\n",
    "        y_tr = Variable(y_tr)   # batch y\n",
    "#         x_tr.requires_grad_()\n",
    "        output,_ = cnn(x_tr)               # cnn output\n",
    "#         print(output)\n",
    "        loss = criterion(output, y_tr)   # cross entropy loss\n",
    "#         print(loss)\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "#         print(x_tr.grad)\n",
    "        optimizer.step()                # apply gradients\n",
    "        \n",
    "    x_te = test_input.narrow(0, b, mini_batch_size)#.narrow(1, 0, 1)\n",
    "    y_te = test_target.narrow(0, b, mini_batch_size)#.narrow(1, 0, 1).squeeze()\n",
    "    x_te = Variable(x_te)   \n",
    "    y_te = Variable(y_te)   \n",
    "\n",
    "    \n",
    "    y_tr_pred = torch.max(output, 1)[1].data.squeeze()\n",
    "    acc_tr = (y_tr_pred == y_tr).sum().data.item() / y_tr.size(0)\n",
    "    \n",
    "    test_output, last_layer = cnn(x_te)    \n",
    "    y_te_pred = torch.max(test_output, 1)[1].data.squeeze()\n",
    "    acc_te = (y_te_pred == y_te).sum().data.item() / y_te.size(0)\n",
    "    print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.item(), '| train accuracy: %.4f' % acc_tr, '| test accuracy: %.2f' % acc_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# following function (plot_with_labels) is for visualization, can be ignored if not interested\n",
    "from matplotlib import cm\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_with_labels(lowDWeights, labels):\n",
    "    plt.cla()\n",
    "    X, Y = lowDWeights[:, 0], lowDWeights[:, 1]\n",
    "    for x, y, s in zip(X, Y, labels):\n",
    "        c = cm.rainbow(int(255 * s / 9)); plt.text(x, y, s, backgroundcolor=c, fontsize=9)\n",
    "    plt.xlim(X.min(), X.max()); plt.ylim(Y.min(), Y.max()); plt.title('Visualize last layer'); plt.show(); plt.pause(0.01)\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "plot_only = 500\n",
    "low_dim_embs = tsne.fit_transform(last_layer.data.numpy()[:plot_only, :])\n",
    "labels = y_te.numpy()[:plot_only]\n",
    "plot_with_labels(low_dim_embs, labels)\n",
    "plt.ioff()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
