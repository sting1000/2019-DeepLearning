{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Drop out;\n",
    "2. Data augmentation;\n",
    "3. Weight sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "# standard library\n",
    "import os\n",
    " \n",
    "# third-party library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlc_practical_prologue as helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = helper.generate_pair_sets(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1                   # filter movement/step\n",
    "                              # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=3),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 3 , 1, 1),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 2 * 2, 10)   # fully connected layer, output 10 classes\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        output = self.out(x)\n",
    "        return output,x    # return x for visualization  \n",
    "cnn = CNN()\n",
    "print(cnn)  # net architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = train_classes.view(-1)\n",
    "train_input = train_input.view(-1,1,14,14)\n",
    "\n",
    "test_classes = test_classes.view(-1)\n",
    "test_input = test_input.view(-1,1,14,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class rotated_dataset(Data.Dataset):\n",
    "\n",
    "    def __init__(self, data, transform):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        item = self.transform(item)\n",
    "        return item\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = train_classes.view(-1)\n",
    "train_input = train_input.view(-1,1,14,14)\n",
    "augumented_data = rotated_dataset(train_input, transform)\n",
    "\n",
    "train_new = torch.cat((train_input,augumented_data.data),0)\n",
    "train_classes_new = torch.cat((train_classes, train_classes), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes = test_classes.view(-1)\n",
    "test_input = test_input.view(-1,1,14,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.0869 | train accuracy: 0.97\n",
      "Epoch:  0 | test loss: 0.0366 | test accuracy: 0.98 \n",
      "\n",
      "\n",
      "Epoch:  1 | train loss: 0.2015 | train accuracy: 0.98\n",
      "Epoch:  1 | test loss: 0.1572 | test accuracy: 0.98 \n",
      "\n",
      "\n",
      "Epoch:  2 | train loss: 0.0020 | train accuracy: 1.00\n",
      "Epoch:  2 | test loss: 0.3598 | test accuracy: 0.96 \n",
      "\n",
      "\n",
      "Epoch:  3 | train loss: 0.0000 | train accuracy: 1.00\n",
      "Epoch:  3 | test loss: 0.3439 | test accuracy: 0.95 \n",
      "\n",
      "\n",
      "Epoch:  4 | train loss: 0.1389 | train accuracy: 0.98\n",
      "Epoch:  4 | test loss: 0.2753 | test accuracy: 0.96 \n",
      "\n",
      "\n",
      "Epoch:  5 | train loss: 0.0686 | train accuracy: 0.99\n",
      "Epoch:  5 | test loss: 0.2905 | test accuracy: 0.96 \n",
      "\n",
      "\n",
      "Epoch:  6 | train loss: 0.0000 | train accuracy: 1.00\n",
      "Epoch:  6 | test loss: 0.3501 | test accuracy: 0.98 \n",
      "\n",
      "\n",
      "Epoch:  7 | train loss: 0.0285 | train accuracy: 0.99\n",
      "Epoch:  7 | test loss: 0.6543 | test accuracy: 0.96 \n",
      "\n",
      "\n",
      "Epoch:  8 | train loss: 0.0010 | train accuracy: 1.00\n",
      "Epoch:  8 | test loss: 0.4816 | test accuracy: 0.97 \n",
      "\n",
      "\n",
      "Epoch:  9 | train loss: 0.0003 | train accuracy: 1.00\n",
      "Epoch:  9 | test loss: 0.3858 | test accuracy: 0.96 \n",
      "\n",
      "\n",
      "Epoch:  10 | train loss: 0.0005 | train accuracy: 1.00\n",
      "Epoch:  10 | test loss: 1.0189 | test accuracy: 0.93 \n",
      "\n",
      "\n",
      "Epoch:  11 | train loss: 0.0590 | train accuracy: 0.99\n",
      "Epoch:  11 | test loss: 0.5240 | test accuracy: 0.94 \n",
      "\n",
      "\n",
      "Epoch:  12 | train loss: 0.0093 | train accuracy: 0.99\n",
      "Epoch:  12 | test loss: 0.2785 | test accuracy: 0.98 \n",
      "\n",
      "\n",
      "Epoch:  13 | train loss: 0.0085 | train accuracy: 1.00\n",
      "Epoch:  13 | test loss: 0.3494 | test accuracy: 0.98 \n",
      "\n",
      "\n",
      "Epoch:  14 | train loss: 0.0007 | train accuracy: 1.00\n",
      "Epoch:  14 | test loss: 0.5180 | test accuracy: 0.96 \n",
      "\n",
      "\n",
      "Epoch:  15 | train loss: 0.0002 | train accuracy: 1.00\n",
      "Epoch:  15 | test loss: 0.4388 | test accuracy: 0.97 \n",
      "\n",
      "\n",
      "Epoch:  16 | train loss: 0.0142 | train accuracy: 0.99\n",
      "Epoch:  16 | test loss: 0.5758 | test accuracy: 0.95 \n",
      "\n",
      "\n",
      "Epoch:  17 | train loss: 0.0024 | train accuracy: 1.00\n",
      "Epoch:  17 | test loss: 0.4662 | test accuracy: 0.96 \n",
      "\n",
      "\n",
      "Epoch:  18 | train loss: 0.0001 | train accuracy: 1.00\n",
      "Epoch:  18 | test loss: 0.5641 | test accuracy: 0.95 \n",
      "\n",
      "\n",
      "Epoch:  19 | train loss: 0.0000 | train accuracy: 1.00\n",
      "Epoch:  19 | test loss: 0.7850 | test accuracy: 0.94 \n",
      "\n",
      "\n",
      "Epoch:  20 | train loss: 0.0062 | train accuracy: 1.00\n",
      "Epoch:  20 | test loss: 0.5164 | test accuracy: 0.96 \n",
      "\n",
      "\n",
      "Epoch:  21 | train loss: 0.0000 | train accuracy: 1.00\n",
      "Epoch:  21 | test loss: 0.4110 | test accuracy: 0.98 \n",
      "\n",
      "\n",
      "Epoch:  22 | train loss: 0.0000 | train accuracy: 1.00\n",
      "Epoch:  22 | test loss: 0.7543 | test accuracy: 0.95 \n",
      "\n",
      "\n",
      "Epoch:  23 | train loss: 0.0000 | train accuracy: 1.00\n",
      "Epoch:  23 | test loss: 0.9099 | test accuracy: 0.94 \n",
      "\n",
      "\n",
      "Epoch:  24 | train loss: 0.0002 | train accuracy: 1.00\n",
      "Epoch:  24 | test loss: 0.3895 | test accuracy: 0.96 \n",
      "\n",
      "\n",
      "Epoch:  25 | train loss: 0.0001 | train accuracy: 1.00\n",
      "Epoch:  25 | test loss: 0.8167 | test accuracy: 0.92 \n",
      "\n",
      "\n",
      "Epoch:  26 | train loss: 0.2125 | train accuracy: 0.98\n",
      "Epoch:  26 | test loss: 0.5759 | test accuracy: 0.93 \n",
      "\n",
      "\n",
      "Epoch:  27 | train loss: 0.1649 | train accuracy: 0.98\n",
      "Epoch:  27 | test loss: 0.4151 | test accuracy: 0.96 \n",
      "\n",
      "\n",
      "Epoch:  28 | train loss: 0.0771 | train accuracy: 0.99\n",
      "Epoch:  28 | test loss: 0.4585 | test accuracy: 0.97 \n",
      "\n",
      "\n",
      "Epoch:  29 | train loss: 0.0246 | train accuracy: 0.99\n",
      "Epoch:  29 | test loss: 0.4342 | test accuracy: 0.95 \n",
      "\n",
      "\n",
      "Epoch:  30 | train loss: 0.0807 | train accuracy: 0.98\n",
      "Epoch:  30 | test loss: 1.0041 | test accuracy: 0.96 \n",
      "\n",
      "\n",
      "Epoch:  31 | train loss: 0.1742 | train accuracy: 0.97\n",
      "Epoch:  31 | test loss: 0.4724 | test accuracy: 0.96 \n",
      "\n",
      "\n",
      "Epoch:  32 | train loss: 0.0377 | train accuracy: 0.98\n",
      "Epoch:  32 | test loss: 1.2333 | test accuracy: 0.90 \n",
      "\n",
      "\n",
      "Epoch:  33 | train loss: 0.1403 | train accuracy: 0.98\n",
      "Epoch:  33 | test loss: 1.2493 | test accuracy: 0.94 \n",
      "\n",
      "\n",
      "Epoch:  34 | train loss: 0.3394 | train accuracy: 0.97\n",
      "Epoch:  34 | test loss: 0.8202 | test accuracy: 0.97 \n",
      "\n",
      "\n",
      "Epoch:  35 | train loss: 0.0000 | train accuracy: 1.00\n",
      "Epoch:  35 | test loss: 1.4644 | test accuracy: 0.92 \n",
      "\n",
      "\n",
      "Epoch:  36 | train loss: 0.0002 | train accuracy: 1.00\n",
      "Epoch:  36 | test loss: 0.4995 | test accuracy: 0.94 \n",
      "\n",
      "\n",
      "Epoch:  37 | train loss: 0.0001 | train accuracy: 1.00\n",
      "Epoch:  37 | test loss: 0.8874 | test accuracy: 0.94 \n",
      "\n",
      "\n",
      "Epoch:  38 | train loss: 0.0200 | train accuracy: 0.99\n",
      "Epoch:  38 | test loss: 0.7621 | test accuracy: 0.95 \n",
      "\n",
      "\n",
      "Epoch:  39 | train loss: 0.3164 | train accuracy: 0.95\n",
      "Epoch:  39 | test loss: 1.1664 | test accuracy: 0.92 \n",
      "\n",
      "\n",
      "Epoch:  40 | train loss: 0.0026 | train accuracy: 1.00\n",
      "Epoch:  40 | test loss: 0.8584 | test accuracy: 0.93 \n",
      "\n",
      "\n",
      "Epoch:  41 | train loss: 0.0001 | train accuracy: 1.00\n",
      "Epoch:  41 | test loss: 1.0320 | test accuracy: 0.95 \n",
      "\n",
      "\n",
      "Epoch:  42 | train loss: 0.0001 | train accuracy: 1.00\n",
      "Epoch:  42 | test loss: 0.7388 | test accuracy: 0.95 \n",
      "\n",
      "\n",
      "Epoch:  43 | train loss: 0.0000 | train accuracy: 1.00\n",
      "Epoch:  43 | test loss: 0.9009 | test accuracy: 0.97 \n",
      "\n",
      "\n",
      "Epoch:  44 | train loss: 0.0339 | train accuracy: 0.99\n",
      "Epoch:  44 | test loss: 0.8025 | test accuracy: 0.95 \n",
      "\n",
      "\n",
      "Epoch:  45 | train loss: 0.0142 | train accuracy: 0.99\n",
      "Epoch:  45 | test loss: 0.5732 | test accuracy: 0.97 \n",
      "\n",
      "\n",
      "Epoch:  46 | train loss: 0.1836 | train accuracy: 0.98\n",
      "Epoch:  46 | test loss: 1.1311 | test accuracy: 0.95 \n",
      "\n",
      "\n",
      "Epoch:  47 | train loss: 0.0622 | train accuracy: 0.99\n",
      "Epoch:  47 | test loss: 0.5879 | test accuracy: 0.97 \n",
      "\n",
      "\n",
      "Epoch:  48 | train loss: 0.0075 | train accuracy: 0.99\n",
      "Epoch:  48 | test loss: 0.8462 | test accuracy: 0.95 \n",
      "\n",
      "\n",
      "Epoch:  49 | train loss: 0.0000 | train accuracy: 1.00\n",
      "Epoch:  49 | test loss: 0.7759 | test accuracy: 0.96 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mini_batch_size=100\n",
    "EPOCH = 50\n",
    "LR = 0.005              # learning rate\n",
    "step = 0\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "criterion = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for b in range(0, train_input.size(0), mini_batch_size):   # gives batch data, normalize x when iterate train_loader\n",
    "        \n",
    "        x_tr = train_new.narrow(0, b, mini_batch_size).narrow(1, 0, 1)\n",
    "        y_tr = train_classes_new.narrow(0, b, mini_batch_size)#.narrow(1, 0, 1).squeeze()\n",
    "        x_tr = Variable(x_tr)   # batch x\n",
    "        y_tr = Variable(y_tr)   # batch y\n",
    "        \n",
    "        output,last_layer = cnn(x_tr)               # cnn output\n",
    "        loss = criterion(output, y_tr)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        \n",
    "    x_te = test_input.narrow(0, b, mini_batch_size).narrow(1, 0, 1)\n",
    "    y_te = test_classes.narrow(0, b, mini_batch_size)#.narrow(1, 0, 1).squeeze()\n",
    "    x_te = Variable(x_te)   \n",
    "    y_te = Variable(y_te)   \n",
    "    \n",
    "    y_tr_pred = torch.max(output, 1)[1].data.squeeze()\n",
    "    acc_tr = (y_tr_pred == y_tr).sum().data.item() / y_tr.size(0)\n",
    "    \n",
    "    test_output,last_layer = cnn(x_te)\n",
    "    test_loss = criterion(test_output, y_te)\n",
    "    y_te_pred = torch.max(test_output, 1)[1].data.squeeze()\n",
    "    acc_te = (y_te_pred == y_te).sum().data.item() / y_te.size(0)\n",
    "    print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.item(), '| train accuracy: %.2f' % acc_tr)\n",
    "    print('Epoch: ', epoch, '| test loss: %.4f' % test_loss.data.item(), '| test accuracy: %.2f' % acc_te,'\\n\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# following function (plot_with_labels) is for visualization, can be ignored if not interested\n",
    "from matplotlib import cm\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_with_labels(lowDWeights, labels):\n",
    "    plt.cla()\n",
    "    X, Y = lowDWeights[:, 0], lowDWeights[:, 1]\n",
    "    for x, y, s in zip(X, Y, labels):\n",
    "        c = cm.rainbow(int(255 * s / 9)); plt.text(x, y, s, backgroundcolor=c, fontsize=9)\n",
    "    plt.xlim(X.min(), X.max()); plt.ylim(Y.min(), Y.max()); plt.title('Visualize last layer'); plt.show(); plt.pause(0.01)\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "plot_only = 500\n",
    "low_dim_embs = tsne.fit_transform(last_layer.data.numpy()[:plot_only, :])\n",
    "labels = y_te.numpy()[:plot_only]\n",
    "plot_with_labels(low_dim_embs, labels)\n",
    "plt.ioff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2, 14, 14])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input = train_input.view(-1,2,14,14)\n",
    "test_input = test_input.view(-1,2,14,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output,_ = cnn(train_input)\n",
    "y_tr_pred = torch.max(train_output, 1)[1].data.squeeze()\n",
    "\n",
    "test_output,_ = cnn(test_input) \n",
    "y_te_pred = torch.max(test_output, 1)[1].data.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_tr = (y_tr_pred[::2] <= y_tr_pred[1::2])\n",
    "y_te = (y_te_pred[::2] <= y_te_pred[1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.996"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_tr = (y_tr.float() == train_target.float()).sum().data.item() / y_tr.size(0)\n",
    "acc_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_te = (y_te.float() == test_target.float()).sum().data.item() / y_te.size(0)\n",
    "acc_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "当第一个数字小于第二个时判1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN2(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(2, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=20, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (tanh): Tanh()\n",
      "  (out): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=2,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1                   # filter movement/step\n",
    "                              # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=3),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 3 , 1, 1),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(32 * 2 * 2, 20)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "#         self.tanh = nn.Tanh()\n",
    "        self.out = nn.Linear(20, 1)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.fc1(x)\n",
    "        output = self.tanh(self.out(x))\n",
    "        return output   # return x for visualization  \n",
    "cnn2 = CNN2()\n",
    "print(cnn2)  # net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /Users/soumith/mc3build/conda-bld/pytorch_1549597882250/work/aten/src/THNN/generic/ClassNLLCriterion.c:93",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-230cd833160b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# cnn output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# cross entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# clear gradients for this training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# backpropagation, compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 904\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1788\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1789\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /Users/soumith/mc3build/conda-bld/pytorch_1549597882250/work/aten/src/THNN/generic/ClassNLLCriterion.c:93"
     ]
    }
   ],
   "source": [
    "mini_batch_size=100\n",
    "EPOCH = 20\n",
    "LR = 0.0001              # learning rate\n",
    "step = 0\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "criterion = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for b in range(0, train_input.size(0), mini_batch_size):   # gives batch data, normalize x when iterate train_loader\n",
    "        \n",
    "        x_tr = train_input.narrow(0, b, mini_batch_size)\n",
    "        y_tr = train_target.narrow(0, b, mini_batch_size)\n",
    "        x_tr = Variable(x_tr)   # batch x\n",
    "        y_tr = Variable(y_tr)   # batch y\n",
    "        \n",
    "        output = cnn2(x_tr)           # cnn output\n",
    "        loss = criterion(output,y_tr)  # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        \n",
    "    x_te = test_input.narrow(0, b, mini_batch_size).narrow(1, 0, 1)\n",
    "    y_te = test_classes.narrow(0, b, mini_batch_size).narrow(1, 0, 1).squeeze()\n",
    "    x_te = Variable(x_te)   \n",
    "    y_te = Variable(y_te)   \n",
    "\n",
    "    y_tr_pred = torch.max(output, 1)[1].data.squeeze()\n",
    "    acc_tr = (y_tr_pred == y_tr).sum().data.item() / y_tr.size(0)\n",
    "    \n",
    "    test_output, last_layer = cnn(x_te)    \n",
    "    y_te_pred = torch.max(test_output, 1)[1].data.squeeze()\n",
    "    acc_te = (y_te_pred == y_te).sum().data.item() / y_te.size(0)\n",
    "    print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.item(), '| train accuracy: %.2f' % acc_tr, '| test accuracy: %.2f' % acc_te)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiameseNetwork(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1                   # filter movement/step\n",
    "                              # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=3),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 3 , 1, 1),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 2 * 2, 10)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n",
    "model = SiameseNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_size=100\n",
    "EPOCH = 50\n",
    "LR = 0.005              # learning rate\n",
    "step = 0\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "criterion = nn.ContrastiveLoss()                       # the target label is not one-hotted\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for b in range(0, train_input.size(0), mini_batch_size):   # gives batch data, normalize x when iterate train_loader\n",
    "        \n",
    "        x_tr = train_input.narrow(0, b, mini_batch_size)\n",
    "        y_tr = train_classes.narrow(0, b, mini_batch_size)\n",
    "        x_tr = Variable(x_tr)   # batch x\n",
    "        y_tr = Variable(y_tr)   # batch y\n",
    "        \n",
    "        output1,output2 = model(x_tr.narrow(1,0,1),x_tr.narrow(1,1,1))               # cnn output\n",
    "        loss = criterion(torch.cat([output1,output2]), torch.cat([y_tr.transpose(1,0)[0],y_tr.transpose(1,0)[1]]))   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        \n",
    "    x_te = test_input.narrow(0, b, mini_batch_size).narrow(1, 0, 1)\n",
    "    y_te = test_classes.narrow(0, b, mini_batch_size).narrow(1, 0, 1).squeeze()\n",
    "    x_te = Variable(x_te)   \n",
    "    y_te = Variable(y_te)   \n",
    "    \n",
    "    y_tr_pred1 = torch.max(output1, 1)[1].data.squeeze()\n",
    "    y_tr_pred2 = torch.max(output2, 1)[1].data.squeeze()\n",
    "    acc_tr = (y_tr_pred == y_tr).sum().data.item() / y_tr.size(0)\n",
    "    \n",
    "    test_output = model(x_te)    \n",
    "    y_te_pred = torch.max(test_output, 1)[1].data.squeeze()\n",
    "    acc_te = (y_te_pred == y_te).sum().data.item() / y_te.size(0)\n",
    "    print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.item(), '| train accuracy: %.2f' % acc_tr, '| test accuracy: %.2f' % acc_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47.2847, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 0, 1, 6, 3, 2, 3, 7, 4, 1, 9, 5, 7, 1, 9, 6, 3, 5, 4, 1, 1, 2, 2, 8,\n",
       "        4, 8, 2, 5, 9, 2, 6, 4, 9, 0, 1, 9, 5, 3, 9, 7, 1, 5, 8, 3, 9, 8, 0, 6,\n",
       "        6, 2, 1, 3, 9, 1, 8, 4, 0, 3, 5, 8, 6, 4, 7, 8, 8, 3, 7, 9, 3, 7, 5, 5,\n",
       "        9, 9, 8, 5, 0, 3, 2, 1, 1, 0, 6, 2, 8, 1, 8, 9, 4, 7, 5, 7, 3, 6, 8, 9,\n",
       "        9, 3, 1, 7])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.transpose(1,0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'ContrastiveLoss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-02ec49a635b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContrastiveLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'ContrastiveLoss'"
     ]
    }
   ],
   "source": [
    "nn.ContrastiveLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'contrastive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-e65b3655cbea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcontrastive\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContrastiveLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'contrastive'"
     ]
    }
   ],
   "source": [
    "from contrastive import ContrastiveLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = helper.generate_pair_sets(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_classes = train_classes.view(-1)\n",
    "# train_input = train_input.view(-1,1,14,14)\n",
    "augumented_data = rotated_dataset(train_input, transform)\n",
    "\n",
    "train_input = torch.cat((train_input,augumented_data.data),0)#.view(-1,2,14,14)\n",
    "train_classes = torch.cat((train_classes, train_classes), 0)\n",
    "train_target = torch.cat((train_target, train_target), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_binary(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(2, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): Dropout(p=0.5)\n",
      "    (2): ReLU()\n",
      "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Dropout(p=0.5)\n",
      "    (2): ReLU()\n",
      "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Dropout(p=0.5)\n",
      "    (2): ReLU()\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=288, out_features=20, bias=True)\n",
      "  (out): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN_binary(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_binary, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (2, 14, 14)\n",
    "            nn.Conv2d(\n",
    "                in_channels=2,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=2,              # filter size\n",
    "                stride=1                   # filter movement/step\n",
    "                              # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 2 , 1, 1),     # output shape (32, 14, 14)\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(32, 64, 2 , 1, 1),     # output shape (32, 14, 14)\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(32 * 3 * 3, 20)\n",
    "        self.out = nn.Linear(20, 1)   # fully connected layer, output 10 classes\n",
    "        self.bn1 = nn.BatchNorm2d(20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "#         x = self.conv3(x)\n",
    "#         print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        output = self.out(x).squeeze()\n",
    "        return output,x    # return x for visualization  \n",
    "cnn = CNN_binary()\n",
    "print(cnn)  # net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 1.4529 | test loss: 1.3896\n",
      "train accuracy: 0.65 | test accuracy: 0.62 \n",
      "\n",
      "\n",
      "Epoch:  1 | train loss: 1.1783 | test loss: 1.1416\n",
      "train accuracy: 0.61 | test accuracy: 0.67 \n",
      "\n",
      "\n",
      "Epoch:  2 | train loss: 0.9192 | test loss: 1.0094\n",
      "train accuracy: 0.64 | test accuracy: 0.69 \n",
      "\n",
      "\n",
      "Epoch:  3 | train loss: 0.8752 | test loss: 0.8953\n",
      "train accuracy: 0.73 | test accuracy: 0.68 \n",
      "\n",
      "\n",
      "Epoch:  4 | train loss: 0.7499 | test loss: 0.8025\n",
      "train accuracy: 0.71 | test accuracy: 0.72 \n",
      "\n",
      "\n",
      "Epoch:  5 | train loss: 0.7494 | test loss: 0.7914\n",
      "train accuracy: 0.74 | test accuracy: 0.70 \n",
      "\n",
      "\n",
      "Epoch:  6 | train loss: 0.7212 | test loss: 0.7172\n",
      "train accuracy: 0.69 | test accuracy: 0.72 \n",
      "\n",
      "\n",
      "Epoch:  7 | train loss: 0.6901 | test loss: 0.6938\n",
      "train accuracy: 0.73 | test accuracy: 0.72 \n",
      "\n",
      "\n",
      "Epoch:  8 | train loss: 0.7447 | test loss: 0.7045\n",
      "train accuracy: 0.73 | test accuracy: 0.72 \n",
      "\n",
      "\n",
      "Epoch:  9 | train loss: 0.5436 | test loss: 0.6622\n",
      "train accuracy: 0.76 | test accuracy: 0.72 \n",
      "\n",
      "\n",
      "Epoch:  10 | train loss: 0.5734 | test loss: 0.6491\n",
      "train accuracy: 0.76 | test accuracy: 0.76 \n",
      "\n",
      "\n",
      "Epoch:  11 | train loss: 0.6619 | test loss: 0.6514\n",
      "train accuracy: 0.76 | test accuracy: 0.73 \n",
      "\n",
      "\n",
      "Epoch:  12 | train loss: 0.5838 | test loss: 0.6545\n",
      "train accuracy: 0.77 | test accuracy: 0.73 \n",
      "\n",
      "\n",
      "Epoch:  13 | train loss: 0.6292 | test loss: 0.6294\n",
      "train accuracy: 0.72 | test accuracy: 0.75 \n",
      "\n",
      "\n",
      "Epoch:  14 | train loss: 0.6228 | test loss: 0.6226\n",
      "train accuracy: 0.75 | test accuracy: 0.74 \n",
      "\n",
      "\n",
      "Epoch:  15 | train loss: 0.5654 | test loss: 0.6360\n",
      "train accuracy: 0.78 | test accuracy: 0.73 \n",
      "\n",
      "\n",
      "Epoch:  16 | train loss: 0.6166 | test loss: 0.6071\n",
      "train accuracy: 0.75 | test accuracy: 0.75 \n",
      "\n",
      "\n",
      "Epoch:  17 | train loss: 0.5904 | test loss: 0.6104\n",
      "train accuracy: 0.73 | test accuracy: 0.76 \n",
      "\n",
      "\n",
      "Epoch:  18 | train loss: 0.5731 | test loss: 0.5987\n",
      "train accuracy: 0.79 | test accuracy: 0.75 \n",
      "\n",
      "\n",
      "Epoch:  19 | train loss: 0.5256 | test loss: 0.5928\n",
      "train accuracy: 0.78 | test accuracy: 0.76 \n",
      "\n",
      "\n",
      "Epoch:  20 | train loss: 0.5045 | test loss: 0.6041\n",
      "train accuracy: 0.74 | test accuracy: 0.74 \n",
      "\n",
      "\n",
      "Epoch:  21 | train loss: 0.5073 | test loss: 0.5949\n",
      "train accuracy: 0.72 | test accuracy: 0.73 \n",
      "\n",
      "\n",
      "Epoch:  22 | train loss: 0.5066 | test loss: 0.6172\n",
      "train accuracy: 0.78 | test accuracy: 0.74 \n",
      "\n",
      "\n",
      "Epoch:  23 | train loss: 0.5508 | test loss: 0.5818\n",
      "train accuracy: 0.80 | test accuracy: 0.75 \n",
      "\n",
      "\n",
      "Epoch:  24 | train loss: 0.4650 | test loss: 0.5909\n",
      "train accuracy: 0.76 | test accuracy: 0.74 \n",
      "\n",
      "\n",
      "Epoch:  25 | train loss: 0.5285 | test loss: 0.5999\n",
      "train accuracy: 0.74 | test accuracy: 0.74 \n",
      "\n",
      "\n",
      "Epoch:  26 | train loss: 0.4193 | test loss: 0.6242\n",
      "train accuracy: 0.82 | test accuracy: 0.73 \n",
      "\n",
      "\n",
      "Epoch:  27 | train loss: 0.4852 | test loss: 0.5862\n",
      "train accuracy: 0.82 | test accuracy: 0.75 \n",
      "\n",
      "\n",
      "Epoch:  28 | train loss: 0.4489 | test loss: 0.6040\n",
      "train accuracy: 0.81 | test accuracy: 0.76 \n",
      "\n",
      "\n",
      "Epoch:  29 | train loss: 0.4795 | test loss: 0.6028\n",
      "train accuracy: 0.75 | test accuracy: 0.76 \n",
      "\n",
      "\n",
      "Epoch:  30 | train loss: 0.4851 | test loss: 0.6056\n",
      "train accuracy: 0.83 | test accuracy: 0.75 \n",
      "\n",
      "\n",
      "Epoch:  31 | train loss: 0.5123 | test loss: 0.5661\n",
      "train accuracy: 0.82 | test accuracy: 0.77 \n",
      "\n",
      "\n",
      "Epoch:  32 | train loss: 0.5249 | test loss: 0.6085\n",
      "train accuracy: 0.82 | test accuracy: 0.76 \n",
      "\n",
      "\n",
      "Epoch:  33 | train loss: 0.4921 | test loss: 0.5679\n",
      "train accuracy: 0.80 | test accuracy: 0.78 \n",
      "\n",
      "\n",
      "Epoch:  34 | train loss: 0.4434 | test loss: 0.5639\n",
      "train accuracy: 0.79 | test accuracy: 0.75 \n",
      "\n",
      "\n",
      "Epoch:  35 | train loss: 0.5383 | test loss: 0.5982\n",
      "train accuracy: 0.77 | test accuracy: 0.76 \n",
      "\n",
      "\n",
      "Epoch:  36 | train loss: 0.4722 | test loss: 0.5996\n",
      "train accuracy: 0.79 | test accuracy: 0.74 \n",
      "\n",
      "\n",
      "Epoch:  37 | train loss: 0.4743 | test loss: 0.5725\n",
      "train accuracy: 0.75 | test accuracy: 0.76 \n",
      "\n",
      "\n",
      "Epoch:  38 | train loss: 0.5579 | test loss: 0.5695\n",
      "train accuracy: 0.77 | test accuracy: 0.79 \n",
      "\n",
      "\n",
      "Epoch:  39 | train loss: 0.4421 | test loss: 0.5648\n",
      "train accuracy: 0.81 | test accuracy: 0.75 \n",
      "\n",
      "\n",
      "Epoch:  40 | train loss: 0.4357 | test loss: 0.5701\n",
      "train accuracy: 0.76 | test accuracy: 0.76 \n",
      "\n",
      "\n",
      "Epoch:  41 | train loss: 0.4660 | test loss: 0.5559\n",
      "train accuracy: 0.76 | test accuracy: 0.76 \n",
      "\n",
      "\n",
      "Epoch:  42 | train loss: 0.5070 | test loss: 0.5943\n",
      "train accuracy: 0.71 | test accuracy: 0.75 \n",
      "\n",
      "\n",
      "Epoch:  43 | train loss: 0.5136 | test loss: 0.5832\n",
      "train accuracy: 0.69 | test accuracy: 0.75 \n",
      "\n",
      "\n",
      "Epoch:  44 | train loss: 0.4179 | test loss: 0.5776\n",
      "train accuracy: 0.77 | test accuracy: 0.75 \n",
      "\n",
      "\n",
      "Epoch:  45 | train loss: 0.3791 | test loss: 0.5762\n",
      "train accuracy: 0.79 | test accuracy: 0.75 \n",
      "\n",
      "\n",
      "Epoch:  46 | train loss: 0.4318 | test loss: 0.5592\n",
      "train accuracy: 0.80 | test accuracy: 0.77 \n",
      "\n",
      "\n",
      "Epoch:  47 | train loss: 0.4257 | test loss: 0.5702\n",
      "train accuracy: 0.79 | test accuracy: 0.75 \n",
      "\n",
      "\n",
      "Epoch:  48 | train loss: 0.4852 | test loss: 0.5908\n",
      "train accuracy: 0.80 | test accuracy: 0.77 \n",
      "\n",
      "\n",
      "Epoch:  49 | train loss: 0.4174 | test loss: 0.5454\n",
      "train accuracy: 0.74 | test accuracy: 0.76 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mini_batch_size=100\n",
    "EPOCH = 50\n",
    "LR = 0.01              # learning rate\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss1 = nn.BCEWithLogitsLoss()                       \n",
    "loss2 = nn.CrossEntropyLoss()\n",
    "\n",
    "m = nn.Sigmoid()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for b in range(0, train_input.size(0), mini_batch_size):   # gives batch data, normalize x when iterate train_loader\n",
    "        \n",
    "        x_tr = train_input.narrow(0, b, mini_batch_size)#.narrow(1, 0, 1)\n",
    "        y_tr = train_target.narrow(0, b, mini_batch_size).float()#.narrow(1, 0, 1).squeeze()\n",
    "        x_tr = Variable(x_tr)   # batch x\n",
    "        y_tr = Variable(y_tr)   # batch y\n",
    "        y_tr_class = train_classes.narrow(0, b, mini_batch_size)\n",
    "        y_tr_class = Variable(y_tr_class)\n",
    "        \n",
    "        output,last_layer = cnn(x_tr)               # cnn output\n",
    "        loss = 0.3*loss1(output, y_tr) + 0.35*loss2(last_layer.narrow(1,0,10),y_tr_class.narrow(1,0,1).squeeze()) + 0.35*loss2(last_layer.narrow(1,10,10),y_tr_class.narrow(1,1,1).squeeze())\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        \n",
    "    x_te = test_input#.narrow(0, b, mini_batch_size)#.narrow(1, 0, 1)\n",
    "    y_te = test_target#.narrow(0, b, mini_batch_size).float()#.narrow(1, 0, 1).squeeze()\n",
    "    x_te = Variable(x_te)   \n",
    "    y_te = Variable(y_te)   \n",
    "\n",
    "    y_tr_pred = (m(output)>0.5).float()\n",
    "    acc_tr = (y_tr_pred == y_tr).sum().data.item() / y_tr.size(0)\n",
    "    \n",
    "    test_output,test_last_layer = cnn(x_te)\n",
    "    y_te_class = test_classes#.narrow(0, b, mini_batch_size)\n",
    "    y_te_class = Variable(y_te_class)\n",
    "    loss_te = 0.3*loss1(test_output, y_te.float()) + 0.35*loss2(test_last_layer.narrow(1,0,10),y_te_class.narrow(1,0,1).squeeze()) + 0.35*loss2(test_last_layer.narrow(1,10,10),y_te_class.narrow(1,1,1).squeeze())\n",
    "    y_te_pred = (m(test_output)>0.5).float()\n",
    "    acc_te = (y_te_pred == y_te.float()).sum().data.item() / y_te.size(0)\n",
    "    print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.item(), '| test loss: %.4f' % loss_te.data.item())\n",
    "    print('train accuracy: %.2f' % acc_tr, '| test accuracy: %.2f' % acc_te,'\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
