{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Drop out;\n",
    "2. Data augmentation;\n",
    "3. Weight sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "# standard library\n",
    "import os\n",
    "\n",
    "# third-party library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlc_practical_prologue as helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Siamese network with auxiliary loss\n",
    "\n",
    "We do not use drop out in siamese network because we cannot promise for one pair of images, for each image the same nodes are dropped out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "class rotated_dataset(Data.Dataset):\n",
    "\n",
    "    def __init__(self, data, transform):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        item = self.transform(item)\n",
    "        return item\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output,_,_,_,_ = model(input.narrow(0, b, mini_batch_size))\n",
    "        target_patch = target.narrow(0, b, mini_batch_size)#.float()\n",
    "        _,output = output.max(1)\n",
    "        nb_errors += (output != target_patch).sum().data.item()\n",
    "    return nb_errors/target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Siamese(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (out): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN_Siamese(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Siamese, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (2, 14, 14)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=32,            # n_filters\n",
    "                kernel_size=2,              # filter size\n",
    "                stride=1                   # filter movement/step\n",
    "                              # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "#             nn.Dropout(0.5),\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(32, 64, 2, 1, 1),     # output shape (32, 14, 14)\n",
    "#             nn.Dropout(0.5),\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(64, 128, 2, 1, 1),     # output shape (32, 14, 14)\n",
    "#             nn.Dropout(0.5),\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(128 *2 * 2, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "        self.out = nn.Linear(20,2)\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        output = self.fc2(x)\n",
    "        return output,x\n",
    "    \n",
    "    def forward(self,x):\n",
    "        input1 = x.narrow(1,0,1)\n",
    "        input2 = x.narrow(1,1,1)\n",
    "        output1,last_layer1 = self.forward_once(input1)\n",
    "        output2,last_layer2 = self.forward_once(input2)\n",
    "        output = torch.cat([output1,output2],dim=1)\n",
    "        output = self.out(output).squeeze()\n",
    "        return output,output1,output2,last_layer1,last_layer2\n",
    "        \n",
    "cnn_siamese = CNN_Siamese()\n",
    "print(cnn_siamese)  # net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74836\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in cnn_siamese.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsample.transforms import RandomTranslate\n",
    "# translate = RandomTranslate(translation_range=(0.3, 0.3))\n",
    "# translated_train = torch.zeros(1000, 2, 14, 14)\n",
    "# translated_test = torch.zeros(1000, 2, 14, 14)\n",
    "# for i in range(1000):\n",
    "#     translated_train[i,:,:,:] = translate(train_input[i,:,:,:])\n",
    "#     translated_test[i,:,:,:] = translate(test_input[i,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = helper.generate_pair_sets(1000)\n",
    "\n",
    "augumented_data = rotated_dataset(train_input, transform)\n",
    "shuffle_index = torch.randperm(1000)\n",
    "train_input = torch.cat((train_input,augumented_data.data),0)\n",
    "train_classes = torch.cat((train_classes, train_classes), 0)\n",
    "train_target = torch.cat((train_target, train_target), 0)\n",
    "\n",
    "train_input, train_classes, train_target = train_input[shuffle_index], train_classes[shuffle_index], train_target[shuffle_index]\n",
    "\n",
    "augumented_data = rotated_dataset(test_input, transform)\n",
    "shuffle_index = torch.randperm(1000)\n",
    "test_input = torch.cat((test_input,augumented_data.data),0)\n",
    "test_classes = torch.cat((test_classes, test_classes), 0)\n",
    "test_target = torch.cat((test_target, test_target), 0)\n",
    "test_input, test_classes, test_target = test_input[shuffle_index], test_classes[shuffle_index], test_target[shuffle_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #2 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-217-63a83f994d92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 904\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1788\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1789\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'target'"
     ]
    }
   ],
   "source": [
    "criterion(output,y_tr_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_class.narrow(1,0,1).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 1, 4, 9, 4, 7, 0, 4, 7, 9, 5, 9, 8, 6, 8, 7, 2, 2, 0, 5, 3, 2, 2, 3,\n",
       "        6, 6, 4, 4, 6, 0, 4, 6, 6, 8, 5, 1, 8, 6, 6, 5, 5, 2, 6, 7, 1, 0, 1, 3,\n",
       "        0, 3, 5, 7, 2, 8, 1, 7, 1, 4, 0, 9, 5, 1, 5, 9, 0, 1, 1, 0, 8, 8, 3, 4,\n",
       "        3, 6, 2, 7, 1, 6, 6, 0, 4, 6, 1, 0, 3, 5, 4, 2, 1, 8, 9, 2, 3, 4, 6, 4,\n",
       "        9, 9, 7, 7], dtype=torch.int32)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_class.narrow(1,0,1).squeeze().int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 1])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.narrow(0, b, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 5.5094 | train error: 0.41\n",
      "Epoch:  0 | test error: 0.43 \n",
      "\n",
      "\n",
      "Epoch:  1 | train loss: 4.8966 | train error: 0.39\n",
      "Epoch:  1 | test error: 0.42 \n",
      "\n",
      "\n",
      "Epoch:  2 | train loss: 3.5834 | train error: 0.40\n",
      "Epoch:  2 | test error: 0.43 \n",
      "\n",
      "\n",
      "Epoch:  3 | train loss: 2.4093 | train error: 0.35\n",
      "Epoch:  3 | test error: 0.38 \n",
      "\n",
      "\n",
      "Epoch:  4 | train loss: 1.6804 | train error: 0.29\n",
      "Epoch:  4 | test error: 0.34 \n",
      "\n",
      "\n",
      "Epoch:  5 | train loss: 1.2847 | train error: 0.27\n",
      "Epoch:  5 | test error: 0.31 \n",
      "\n",
      "\n",
      "Epoch:  6 | train loss: 1.0018 | train error: 0.24\n",
      "Epoch:  6 | test error: 0.27 \n",
      "\n",
      "\n",
      "Epoch:  7 | train loss: 0.9962 | train error: 0.22\n",
      "Epoch:  7 | test error: 0.24 \n",
      "\n",
      "\n",
      "Epoch:  8 | train loss: 0.8047 | train error: 0.21\n",
      "Epoch:  8 | test error: 0.24 \n",
      "\n",
      "\n",
      "Epoch:  9 | train loss: 0.7350 | train error: 0.18\n",
      "Epoch:  9 | test error: 0.22 \n",
      "\n",
      "\n",
      "Epoch:  10 | train loss: 0.7115 | train error: 0.17\n",
      "Epoch:  10 | test error: 0.20 \n",
      "\n",
      "\n",
      "Epoch:  11 | train loss: 0.6461 | train error: 0.17\n",
      "Epoch:  11 | test error: 0.20 \n",
      "\n",
      "\n",
      "Epoch:  12 | train loss: 0.5989 | train error: 0.15\n",
      "Epoch:  12 | test error: 0.19 \n",
      "\n",
      "\n",
      "Epoch:  13 | train loss: 0.5827 | train error: 0.15\n",
      "Epoch:  13 | test error: 0.19 \n",
      "\n",
      "\n",
      "Epoch:  14 | train loss: 0.6026 | train error: 0.14\n",
      "Epoch:  14 | test error: 0.18 \n",
      "\n",
      "\n",
      "Epoch:  15 | train loss: 0.4642 | train error: 0.13\n",
      "Epoch:  15 | test error: 0.18 \n",
      "\n",
      "\n",
      "Epoch:  16 | train loss: 0.4644 | train error: 0.13\n",
      "Epoch:  16 | test error: 0.19 \n",
      "\n",
      "\n",
      "Epoch:  17 | train loss: 0.3810 | train error: 0.11\n",
      "Epoch:  17 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  18 | train loss: 0.3815 | train error: 0.10\n",
      "Epoch:  18 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  19 | train loss: 0.3193 | train error: 0.08\n",
      "Epoch:  19 | test error: 0.16 \n",
      "\n",
      "\n",
      "Epoch:  20 | train loss: 0.4010 | train error: 0.10\n",
      "Epoch:  20 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  21 | train loss: 0.3004 | train error: 0.10\n",
      "Epoch:  21 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  22 | train loss: 0.5213 | train error: 0.09\n",
      "Epoch:  22 | test error: 0.16 \n",
      "\n",
      "\n",
      "Epoch:  23 | train loss: 0.4287 | train error: 0.09\n",
      "Epoch:  23 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  24 | train loss: 0.3092 | train error: 0.09\n",
      "Epoch:  24 | test error: 0.18 \n",
      "\n",
      "\n",
      "Epoch:  25 | train loss: 0.2519 | train error: 0.10\n",
      "Epoch:  25 | test error: 0.18 \n",
      "\n",
      "\n",
      "Epoch:  26 | train loss: 0.3996 | train error: 0.07\n",
      "Epoch:  26 | test error: 0.18 \n",
      "\n",
      "\n",
      "Epoch:  27 | train loss: 0.3321 | train error: 0.06\n",
      "Epoch:  27 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  28 | train loss: 0.2655 | train error: 0.07\n",
      "Epoch:  28 | test error: 0.16 \n",
      "\n",
      "\n",
      "Epoch:  29 | train loss: 0.2449 | train error: 0.06\n",
      "Epoch:  29 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  30 | train loss: 0.3155 | train error: 0.07\n",
      "Epoch:  30 | test error: 0.18 \n",
      "\n",
      "\n",
      "Epoch:  31 | train loss: 0.2770 | train error: 0.04\n",
      "Epoch:  31 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  32 | train loss: 0.2318 | train error: 0.04\n",
      "Epoch:  32 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  33 | train loss: 0.1890 | train error: 0.05\n",
      "Epoch:  33 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  34 | train loss: 0.3352 | train error: 0.08\n",
      "Epoch:  34 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  35 | train loss: 0.1771 | train error: 0.05\n",
      "Epoch:  35 | test error: 0.16 \n",
      "\n",
      "\n",
      "Epoch:  36 | train loss: 0.1381 | train error: 0.05\n",
      "Epoch:  36 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  37 | train loss: 0.1657 | train error: 0.04\n",
      "Epoch:  37 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  38 | train loss: 0.2724 | train error: 0.04\n",
      "Epoch:  38 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  39 | train loss: 0.1391 | train error: 0.05\n",
      "Epoch:  39 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  40 | train loss: 0.1256 | train error: 0.06\n",
      "Epoch:  40 | test error: 0.18 \n",
      "\n",
      "\n",
      "Epoch:  41 | train loss: 0.2268 | train error: 0.06\n",
      "Epoch:  41 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  42 | train loss: 0.2321 | train error: 0.05\n",
      "Epoch:  42 | test error: 0.18 \n",
      "\n",
      "\n",
      "Epoch:  43 | train loss: 0.2494 | train error: 0.05\n",
      "Epoch:  43 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  44 | train loss: 0.2552 | train error: 0.05\n",
      "Epoch:  44 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  45 | train loss: 0.3236 | train error: 0.06\n",
      "Epoch:  45 | test error: 0.18 \n",
      "\n",
      "\n",
      "Epoch:  46 | train loss: 0.3489 | train error: 0.04\n",
      "Epoch:  46 | test error: 0.18 \n",
      "\n",
      "\n",
      "Epoch:  47 | train loss: 0.1858 | train error: 0.06\n",
      "Epoch:  47 | test error: 0.19 \n",
      "\n",
      "\n",
      "Epoch:  48 | train loss: 0.1556 | train error: 0.04\n",
      "Epoch:  48 | test error: 0.17 \n",
      "\n",
      "\n",
      "Epoch:  49 | train loss: 0.2360 | train error: 0.03\n",
      "Epoch:  49 | test error: 0.17 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = CNN_Siamese()\n",
    "\n",
    "mini_batch_size=100\n",
    "EPOCH = 25\n",
    "LR = 0.005              # learning rate\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "criterion = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "# criterion2 = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for b in range(0, train_input.size(0), mini_batch_size):   # gives batch data, normalize x when iterate train_loader\n",
    "        \n",
    "        x_tr = train_input.narrow(0, b, mini_batch_size)\n",
    "        y_tr_class = train_classes.narrow(0, b, mini_batch_size)\n",
    "        y_tr_target = train_target.narrow(0, b, mini_batch_size)#.float()\n",
    "        x_tr = Variable(x_tr)   # batch x\n",
    "        y_tr_class = Variable(y_tr_class)   # batch y\n",
    "        \n",
    "        output,output1,output2,last_layer1,last_layer2 = model(x_tr)               # cnn output\n",
    "#         loss = criterion(output1, y_tr_class.narrow(1,0,1).squeeze())+criterion(output2, y_tr_class.narrow(1,1,1).squeeze())+criterion2(output,y_tr_target)   # cross entropy loss\n",
    "        loss = criterion(output1, y_tr_class.narrow(1,0,1).squeeze())+criterion(output2, y_tr_class.narrow(1,1,1).squeeze())+criterion(output,y_tr_target)   # cross entropy loss\n",
    "    \n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "    \n",
    "    train_error = compute_nb_errors(model, train_input, train_target, mini_batch_size)\n",
    "    test_error = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "    \n",
    "    print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.item(), '| train error: %.2f' % train_error)\n",
    "    print('Epoch: ', epoch, '| test error: %.2f' % test_error,'\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# following function (plot_with_labels) is for visualization, can be ignored if not interested\n",
    "from matplotlib import cm\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_with_labels(lowDWeights, labels):\n",
    "    plt.cla()\n",
    "    X, Y = lowDWeights[:, 0], lowDWeights[:, 1]\n",
    "    for x, y, s in zip(X, Y, labels):\n",
    "        c = cm.rainbow(int(255 * s / 9)); plt.text(x, y, s, backgroundcolor=c, fontsize=9)\n",
    "    plt.xlim(X.min(), X.max()); plt.ylim(Y.min(), Y.max()); plt.title('Visualize last layer'); plt.show(); plt.pause(0.01)\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "plot_only = 500\n",
    "low_dim_embs = tsne.fit_transform(last_layer1.data.numpy()[:plot_only, :])\n",
    "labels = y_tr_class.narrow(1,0,1).squeeze().numpy()[:plot_only]\n",
    "plot_with_labels(low_dim_embs, labels)\n",
    "plt.ioff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
